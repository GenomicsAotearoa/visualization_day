[
  {
    "objectID": "viz_start_to_finish.html",
    "href": "viz_start_to_finish.html",
    "title": "Start to Finish Visualizing your Data",
    "section": "",
    "text": "Note self: this section should be preceeded by an introduction and explanation to tidytuesday (in the exemplar episode), so that readers have context about where this data came from, why we are using it. This section then actively demonstrates the importance of the community effort of tidytuesday (and contributes to their 2024 aim of being involved in 10+ courses (they achieved 30+)).",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#overview",
    "href": "viz_start_to_finish.html#overview",
    "title": "Start to Finish Visualizing your Data",
    "section": "Overview",
    "text": "Overview\nTogether, we are going to go from start to finish and create a visualization. Start to finish means we will need to explore the data, make decisions involving modifications and transformations, and finally, visualize the data in a meaningful way.\nNote: Just the other day I saw a post on LinkedIn, someone had done a screencast recording of them going through a tidytuesday visualization (in Python!). The poster warns us: “I have to admit, this screencast is 80% me orienting to this week’s data”. The comments section immediately responds that “80% orienting to the data is real life!”\n\nAims\nTo demonstrate the full process of exploratory analysis, data transformation, and visualization.\nGenerate discussion, via questions and exercises, about the data and the validity of our modifications and decisions.\nTo generate a figure that is clear, conveys a message, and is visually appealing.\n\n\nHow this will work\nI will work through all the code required to create the end product visualization. You can follow along exactly, or you can opt to deviate from my example (e.g., during data transformation step you might choose to keep 25 samples while I keep 20, you might choose to use the median while I use the mean). If you are newer to ggplot2, then I recommend you follow exactly. If you are more confident, then modify the code as you see fit.\nYou will be provided with a full and complete copy of all this code, to use as a template for your own work.",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#getting-started",
    "href": "viz_start_to_finish.html#getting-started",
    "title": "Start to Finish Visualizing your Data",
    "section": "Getting started",
    "text": "Getting started\n\nPackages\nFor this section we are going to need dplyr, readr, and ggplot. We can load them separately, or we can load the whole tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nImporting the data\nAll tidytuesday data is available for easy download and importing. The data is generally very well organised (it has already gone through cleaning and is ‘tidy’).\n\nparfumo_data_clean &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-12-10/parfumo_data_clean.csv')\n\nRows: 59325 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): Number, Name, Brand, Concentration, Main_Accords, Top_Notes, Middl...\ndbl  (3): Release_Year, Rating_Value, Rating_Count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#exploratory-analysis",
    "href": "viz_start_to_finish.html#exploratory-analysis",
    "title": "Start to Finish Visualizing your Data",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\nThe first step in exploratory analysis is to understand our data. This is the equivalent of picking up a wrapped present, feeling the weight, how solid it is, maybe giving it a little bit of a shake, and trying to figure out what’s inside. With our data, we are trying to build a light-weight mental model - what each object is storing, whether the data is numeric, are there missing values, are there biases between groups, is the data normally distributed etc., etc.,.\nUseful functions here include dim(), colnames(), head(), summary(), str(), class(), and many others. You will develop a set of favourites and defaults.\n\nparfumo_data_clean |&gt; head()\n\n# A tibble: 6 × 13\n  Number Name         Brand Release_Year Concentration Rating_Value Rating_Count\n  &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 455    Tabac Écarl… Le R…           NA &lt;NA&gt;                    NA           NA\n2 0071   Tidal Pool   CB I…         2004 &lt;NA&gt;                    NA           NA\n3 0154   Pumpkin Pie  CB I…         1998 &lt;NA&gt;                    NA           NA\n4 0162   Wet Stone    CB I…         2006 &lt;NA&gt;                    NA           NA\n5 0171   Chocolate B… CB I…           NA &lt;NA&gt;                    NA           NA\n6 0191   My Birthday… CB I…         1975 &lt;NA&gt;                    NA           NA\n# ℹ 6 more variables: Main_Accords &lt;chr&gt;, Top_Notes &lt;chr&gt;, Middle_Notes &lt;chr&gt;,\n#   Base_Notes &lt;chr&gt;, Perfumers &lt;chr&gt;, URL &lt;chr&gt;\n\nparfumo_data_clean |&gt; summary()\n\n    Number              Name              Brand            Release_Year  \n Length:59325       Length:59325       Length:59325       Min.   :1709   \n Class :character   Class :character   Class :character   1st Qu.:2005   \n Mode  :character   Mode  :character   Mode  :character   Median :2013   \n                                                          Mean   :2006   \n                                                          3rd Qu.:2018   \n                                                          Max.   :2024   \n                                                          NA's   :20316  \n Concentration       Rating_Value     Rating_Count     Main_Accords      \n Length:59325       Min.   : 0.000   Min.   :   2.00   Length:59325      \n Class :character   1st Qu.: 6.900   1st Qu.:   6.00   Class :character  \n Mode  :character   Median : 7.400   Median :  19.00   Mode  :character  \n                    Mean   : 7.347   Mean   :  60.66                     \n                    3rd Qu.: 7.900   3rd Qu.:  62.00                     \n                    Max.   :10.000   Max.   :2732.00                     \n                    NA's   :29279    NA's   :29279                       \n  Top_Notes         Middle_Notes        Base_Notes         Perfumers        \n Length:59325       Length:59325       Length:59325       Length:59325      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     URL           \n Length:59325      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nparfumo_data_clean |&gt; colnames()\n\n [1] \"Number\"        \"Name\"          \"Brand\"         \"Release_Year\" \n [5] \"Concentration\" \"Rating_Value\"  \"Rating_Count\"  \"Main_Accords\" \n [9] \"Top_Notes\"     \"Middle_Notes\"  \"Base_Notes\"    \"Perfumers\"    \n[13] \"URL\"          \n\n\nExercise: Note down your initial conclusions and impressions.\n\nWhat are five things you notice about the data?\nWhat is one question you have about the data? (note: looking for a small, simple question about the dataset, not a hypothesis to test)\nWhat is something that jumps out at you, which you might like to investigate, visualize, or learn about? (This could be a hypothesis to test)\n\n\n\n\n\n\n\nInitial observations and impressions\n\n\n\n\n\nThere are many options, but some things that stood out to me:\n\nThere are NAs! Concentration is almost 80% NA, Rating_Count is almost 50% NA (from the summary() function).\nThere is a mix of numeric and character class data.\nRating_Value looks like it’s a 0-10 scale, with a mean and median around 7.3 - 7.4.\nMeanwhile, the mean and median of Rating_Count are quite different: median of 19 and a mean of 60.\nThe basic structure of the data: perfume name, brand, and then a series of values and then a set of descriptions.\n\nQuestions and assumptions: I’m assuming that Rating_Value is an average, with Rating_Count describing how many individual Ratings contributed to the overall value, but that isn’t explained. It could be a mean or median (or mode!)\n\n\n\n\nBrand Rating\nLooking at the data I was interested in Brand, Rating_Value, and Rating_Count. My aim is to generate a visualization which will show which brands consistently have high ratings for their different products, with the intention that a person with little to no knowledge about perfume (like myself) can get an idea of reliable brands.\nExercise: Mentally visualize what this figure might look like. What are the key components we will need to convey?\n\n\n\n\n\n\nMental visualization\n\n\n\n\n\nNeed to convey the average rating for a brand, as well as the variance. Do not need to visualize all brands, only those with consistently high ratings. Boxplots (and violin plots, jitter plots etc.,) are a good way to show the distribution of scores.\n\n\n\n\nAssessing the means\nA useful place to start will be to look at the average (and here I’ll be using mean) rating value for a brand. To do this we will use the dplyr verbs (functions) to group rows based on which Brand they are from, generate a single summary value (a mean of the Rating_Value) for each Brand, arrange the means from highest to lowest, and then use the head() function to view the output.\n\nparfumo_data_clean |&gt; # Remember that |&gt; is the 'pipe', which passes data\\ to the next function.\n  group_by(Brand) |&gt; # All rows which share the same Brand are now grouped.\n  summarize(avg_Rating = mean(Rating_Value, na.rm = TRUE)) |&gt; # Calculate Brand\\ means\n  arrange(desc(avg_Rating)) |&gt; # Arrange Brands from highest to lowest\n  head()\n\n# A tibble: 6 × 2\n  Brand            avg_Rating\n  &lt;chr&gt;                 &lt;dbl&gt;\n1 Natura                10   \n2 Sarahs Creations      10   \n3 mesOud                 9.47\n4 Bourjois               9.4 \n5 Jehanne Rigaud         9.3 \n6 Max Joacim             9.3 \n\n\nExercise: Discuss these results.\n\n\n\n\n\n\nInterpreting these results\n\n\n\n\n\nNatura and Sarahs Creations share the top score of 10. No need for further analysis, we can all go home and talk about our favourite new perfume brands which are obviously very reliable!\n…Or maybe not.\nSince we use base 10, many surveys and tests tend to be scored out of 10. To see two brands with what look like perfect scores makes me very suspicious, especially given it’s a mean - this would require every single person to have rated every single one of their perfumes as a 10. Either they truly are perfect or, more likely, this is due to a very small number of ratings on a single type of perfume.\n\n\n\nIf you are confident in these results, I recommend you re-run summary() and look at the data. Does it change your opinion?\n\nparfumo_data_clean |&gt; summary()\n\n    Number              Name              Brand            Release_Year  \n Length:59325       Length:59325       Length:59325       Min.   :1709   \n Class :character   Class :character   Class :character   1st Qu.:2005   \n Mode  :character   Mode  :character   Mode  :character   Median :2013   \n                                                          Mean   :2006   \n                                                          3rd Qu.:2018   \n                                                          Max.   :2024   \n                                                          NA's   :20316  \n Concentration       Rating_Value     Rating_Count     Main_Accords      \n Length:59325       Min.   : 0.000   Min.   :   2.00   Length:59325      \n Class :character   1st Qu.: 6.900   1st Qu.:   6.00   Class :character  \n Mode  :character   Median : 7.400   Median :  19.00   Mode  :character  \n                    Mean   : 7.347   Mean   :  60.66                     \n                    3rd Qu.: 7.900   3rd Qu.:  62.00                     \n                    Max.   :10.000   Max.   :2732.00                     \n                    NA's   :29279    NA's   :29279                       \n  Top_Notes         Middle_Notes        Base_Notes         Perfumers        \n Length:59325       Length:59325       Length:59325       Length:59325      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     URL           \n Length:59325      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nThe summary() function is very useful here. Looking at the column for Rating_Value, I can see that the mean and median values are around 7.3-7.4, and the range is 0 - 10. At this time I’m also looking at the Rating_Count variable, and seeing that the range there is 2 - 2,732. That tells me that some perfumes were only rated twice. I’m very suspicious that the brands Natura and Sarahs Creations have only a single perfume which was rated only two or three times, which allows them to get perfect scores. Similarly, any other brand with a score that seems too good to be true could be the result of this low-sampling bias.\nExercise: Is my hypothesis (very high scores are the result of low sampling bias) true? What type of visualization would help us to test this? In the space below, create a quick plot to ask whether there is a low-sampling bias present.\nIf you’d like a reminder, here’s a ggplot template from earlier (though, geom_boxplot() might not be what you are after…):\nggplot(data = penData, mapping = aes(x = species, y = bill_length_mm)) + geom_boxplot()\n\n\n\n\n\n\nSolution\n\n\n\n\n\nI am assuming there is a negative relationship between avg_Rating and Rating_count (fewer ratings allow for a higher avg score). A scatter plot, made with geom_point(), with Rating_Count and Rating_Value on the x and y, is a quick and easy way to visualize a relationship like this.\n\nggplot(data = parfumo_data_clean, mapping = aes(x = Rating_Count, y = Rating_Value)) +\n  geom_point()\n\nWarning: Removed 29279 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWarning: 29279 rows removed. Missing values or values outside the scale range - what is this? This warning appears when we attempt to plot values that are outside of the range of the X or Y axis. However, this warning also appears when there is missing data. In this case we know the range of values is 0 - 10, and from the summary() function know that both the Rating variables have 29,279 missing rows. During our initial look at summary(), we noted approx 30,000 missing rows (NAs), leaving approx 30,000 rows of data. If our initial data set didn’t have missing values, this warning would be concerning.\nWarnings can be suppressed, but since we won’t be keeping them in the final plot it’s not critical and I prefer to leave them showing while working through exploratory analysis plots.\n\n\n\nIt seems there is a relationship between Rating_Value and Rating_Count - one we can probably conceptualize quite well! Scents with fewer ratings exhibit the highest and lowest values. Why is this? Presumably all perfumes receive some very high and very low scores based on personal preference. If a perfume has only a small number of ratings, the rating_value is skewed towards those extreme scores. Perfumes with more ratings are gravitating towards a point just below 7.5. This matches with mean and median Rating_Value of 7.35 and 7.40, respectively, which we noted from the summary() function at the start of this episode. It makes sense that as the number of ratings increases, the average rating converges on a middle-ground.\nImportantly, I think this is reasonable grounds to filter our data based on a Rating_Count threshold, since perfumes with a low Rating_Count can be skewed. I need to define a filter threshold, and I’ll use the median value of Rating_Count (19): rows (perfumes) will only be kept if they have been rated 19 times or more.\n\n\nAn aside\nI’ll also take a guess that there will be relationship between Rating_Count and Release_Year. I imagine that newer perfumes will have more ratings due to the internet, marketing, and population. This is important because if we are filtering based on a Rating_Count threshold, we need to be aware this is reducing the likelihood of older Brands appearing.\n\nggplot(data = parfumo_data_clean, \n        mapping = aes(x = Release_Year, y = Rating_Count)) +\n  geom_point()\n\nWarning: Removed 34977 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nDecisions\nI have decided to filter perfumes/rows based on a criteria of having been rated 19 or more times (based on the median rating_Count of 19). Perfumes rated fewer than 19 times will be excluded from the analysis.\nExercise: Discuss with others - do you agree with the decision to filter like this? Can you propose an alternative method? Is our threshold of 19 reasonable?",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#transformations",
    "href": "viz_start_to_finish.html#transformations",
    "title": "Start to Finish Visualizing your Data",
    "section": "Transformations",
    "text": "Transformations\nTransforming data is a term that includes grouping data (as we did above, for Brands), arranging (sorting), moving or renaming columns, etc.,. It also applies to filtering, which we are about to perform. I think there is a distinction between sorting rows or renaming columns and filtering, which is the removal of data from further analysis, so I’m giving it a separate subsection.\nRemoving data, setting thresholds, removing outliers, defining groups, choosing methods - all of these decisions can have significant impacts on your final results. We must keep this in mind and always be ready to question our decisions. In bioinformatics it is usually plausible to repeat analyses with different decisions, and if we find that our decisions are having a big impact on our results, we need to be mindful of this.\n\nFiltering for low rating counts\nThe summary() function reveals that the median number of Rating_Counts is 19, so I’m choosing to keep only rows which have 19 or more ratings. You may decide to change this number or keep it as is.\nThe code below will use filter() to discard all rows which do not meet the threshold (equal to or greater than 19), and will then repeat the steps we did earlier - grouping perfume by Brand, calculating the average rating for those brands, and returning the highest scores.\n\nparfumo_data_clean |&gt; \n  filter(Rating_Count &gt;= 19 ) |&gt; # keep rows where Rating_Count is\\ greater than or equal to 19.\n  group_by(Brand) |&gt; # Group perfumes by brand\n  summarize(avg_Rating = mean(Rating_Value, na.rm = TRUE)) |&gt; # Calculate a\\ new variable, which is the mean of Rating_Value, label\\ it \"avg_Rating\"\n  arrange(desc(avg_Rating)) |&gt; # Sort the new avg_Rating variable in descending order\n  head()\n\n# A tibble: 6 × 2\n  Brand                      avg_Rating\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 Miyaz Perfume                    8.8 \n2 City Rhythm                      8.7 \n3 Kuschel J / クシェルヨット       8.7 \n4 Snif                             8.7 \n5 Sultan Pasha Attars              8.61\n6 Alafasy                          8.6 \n\n\nThe new average ratings are much more plausible. They are also higher than the mean and median (from the summary() function), which is a good sanity check. If my highest scoring brands were lower than the mean or median, I would know I have made a critical error. This might seem obvious, but it’s important to constantly perform these mental checks.\n\n\n\n\n\n\nSanity Checks\n\n\n\n\n\nSanity checks are a term used in bioinformatics and data science. What are they? Why are they important?\nCompare what we are doing today with a task like cooking a dinner. When cooking we have a constant stream of information from our five senses - we would smell that dairy products had gone too far past their use by date or if something was burning, we can hear the pot boiling over on the stove, feel that the carrot is too woody. In contrast, we have almost no feedback about our data! What’s more, our data is often too large and complex for us to interpret easily - I can’t eyeball a thousand data points and be confident they are normally distributed, for example (well, I could be confident, but that wouldn’t mean I’m correct).\nSanity checks are a way to engage with your data and make sure your results make logical sense. Examples include, but are in no way limited to: confirming data types (dates in date columns) and plausible ranges (human age should be between 0 - 120), checking distributions (especially if a statistical method assumes normality, but also for the presence of outliers), validate relationships (longer genes should probably have more mutations than shorter genes, larger genomes should have larger filesizes), data volume (rows and columns should remain the same between steps - unless you are filtering, treatment vs control groups should have equal numbers).\nSanity checks are an entire arm of bioinformatics and data science, much the same way good visualization is. It’s a skill that takes time and effort to build.\n\n\n\n\n\nTransformations cont\nWe’ve taken the step of removing perfumes that had too few ratings to be accurate. Since we are investigating Brands, rather than individual perfumes, it’s logical to ask whether any Brands are scoring highly because they have only one or two perfumes that perform well (a “one-hit-wonder” brand).\nTo test this hypothesis, we can take advantage of the fact that the summarize() function can simultaneously calculate multiple summaries. We will re-run the code from above, but this time include an additional line so that we can see both the average rating and the number of perfumes contributing to the rating.\n\nparfumo_data_clean |&gt; \n  filter(Rating_Count &gt;= 19 ) |&gt; \n  group_by(Brand) |&gt; \n  summarize(avg_Rating = mean(Rating_Value, na.rm = TRUE),\n            number_Perfumes = n()) |&gt; # The \"n()\" counts the number of rows in\\ the group. \n  arrange(desc(avg_Rating)) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 3\n   Brand                       avg_Rating number_Perfumes\n   &lt;chr&gt;                            &lt;dbl&gt;           &lt;int&gt;\n 1 Miyaz Perfume                     8.8                2\n 2 City Rhythm                       8.7                1\n 3 Kuschel J / クシェルヨット        8.7                1\n 4 Snif                              8.7                1\n 5 Sultan Pasha Attars               8.61               7\n 6 Alafasy                           8.6                1\n 7 Nilafar du Nil                    8.6                2\n 8 Mind Games                        8.58               6\n 9 MAD Parfumeur                     8.57               3\n10 Arabian Oud / العربية للعود       8.55               2\n\n\nI can see an issue here - some of these brands have only one or two perfumes. Conceivably, it would be difficult for brands with e.g., 100 perfumes to consistently receive such high ratings, and they will therefore not show up in this list. This is essentially the same issue dealt with above - having fewer ratings, or fewer products, means an average score can be skewed.\nTo deal with this, I’ve added an arbitrary filtering threshold for a brand to have 20 or more perfumes in order to be considered.\n\nparfumo_data_clean |&gt; \n  filter(Rating_Count &gt;= 19 ) |&gt; \n  group_by(Brand) |&gt; \n  summarize(avg_Rating = round(mean(Rating_Value, na.rm = TRUE), 1),\n            number_Perfumes = n()) |&gt; # summarize() can create multiple columns simultaneously\\ here creating both avg_Rating and number_Perfumes\n  filter(number_Perfumes &gt;= 20) |&gt; \n  arrange(desc(avg_Rating)) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 3\n   Brand                avg_Rating number_Perfumes\n   &lt;chr&gt;                     &lt;dbl&gt;           &lt;int&gt;\n 1 Ensar Oud / Oriscent        8.4              93\n 2 Nabeel                      8.3              22\n 3 Aaron Terence Hughes        8.1              61\n 4 Annette Neuffer             8.1              20\n 5 Chanel                      8.1              83\n 6 Clive Christian             8.1              45\n 7 Roja Parfums                8.1             118\n 8 Widian / AJ Arabia          8.1              21\n 9 Areej Le Doré               8                24\n10 Amouage                     7.9              92\n\n\nExercise: Discuss the legitimacy of this filtering threshold of 20. How does this compare to our previous filtering? What would you do differently?\n\n\n\n\n\n\nA ‘practical’ threshold\n\n\n\n\n\nIt might feel like 20 is an arbitrary number for a threshold (and it is). However, I think this is a fine approach, because we are thinking about the practical or translational nature of our question - 20 perfumes is a) not an unreasonable number for a mean and is b) plenty to choose from if a person was in a store - and that’s the goal of this viz.\n\n\n\n\n\nBrand Rating Data\nAn important thing to remember is that the analyses above didn’t actually modify the data - they were only performing the filtering, calculating the summaries, and printing the result to the screen. No data was modified (permanently).\nHere we will generate a new object to store the data after applying our filtering steps.\n\nkeep_brands &lt;- parfumo_data_clean |&gt; \n  filter(Rating_Count &gt;= 19 ) |&gt; \n  group_by(Brand) |&gt; \n  summarize(avg_Rating = round(mean(Rating_Value, na.rm = TRUE), 1),\n            number_Perfumes = n()) |&gt; \n  filter(number_Perfumes &gt;= 20) |&gt; \n  arrange(desc(avg_Rating)) |&gt; \n  head(n = 10)\n\n# Below, filter is checking whether the element in the Brand column is in keep_brands. \nperfume_brand_data &lt;- parfumo_data_clean |&gt; \n  filter(Brand %in% keep_brands$Brand)\n\nkeep_brands |&gt; rm()\n\nExercise: Take five minutes to look at this code and predict the output - do you understand what we have done here? Manipulating objects like this is a critical skill. Take one more look at the code and make sure you understand each line of code and what the output is. Use head(), summary() or any other functions to check the output. Note any observations.\n\n\n\n\n\n\nObservations\n\n\n\n\n\nThe above lines of code are: - Creating a new object, “keep_brands”.\n\nFiltering the parfumo object to keep only those perfumes with a Rating_Count of 19 or greater.\nGrouping perfumes by brand.\nThe summarize() function is creating two new variables: avg_Rating, which is the overall average rating for a Brand and number_Perfumes, which is the number of perfumes that were rated for this brand.\nAnother filter(), this time keeping only those brands with 20 or more perfumes (which have a Rating_Count of 19 or more).\nArrange (sort) the brands by their overall score (from highest to lowest), and keep only the top 10 brands.\n\nkeep_brands is therefore the 10 perfume brands we are interested in: after filtering, they have the highest average rating. Because of how summarize() works, keep_brands only has the new variables we created - avg_Rating and number_Perfumes (plus the Brand names).\nNext, use the Brand variable in keep_brands to pull out all the data from parfumo_data_clean. Here, filter() is being used just like above, but instead of filtering on a “greater than” threshold, we are filtering on whether or not the parfumo_data_clean Brand element is found in the keep_brand object.\nThis has introduced a critical error. It has kept only the brands we want, but we have not specified that we only want those perfumes with a Rating_Count of 19 or more (we have filtered for all perfumes produced by the brands we selected).\nIt is very easy to make a mistake like this\nWhich is why we must always be thinking of sanity checks. The summary() function shows us that the min value in Rating_Count is 2, which is how I realised that somewhere, I’d lost my filtering threshold.\nperfume_brand_data |&gt; summary()\n\n\n\nAnd now we will create a second object which includes our data in an alternative format:\n\nbrandRatingData &lt;- parfumo_data_clean |&gt; \n  filter(Rating_Count &gt;= 19 ) |&gt; \n  group_by(Brand) |&gt; \n  summarize(avg_Rating = mean(Rating_Value, na.rm = TRUE),\n            number_Perfumes = n()) |&gt; \n  filter(number_Perfumes &gt;= 20) |&gt; \n  arrange(desc(avg_Rating)) |&gt; \n  head(n = 20)\n\nBefore you run this next line of code - what data do you expect to see?\nReading through the code above describe, as accurately as you can, what is and is not included in the brandRatingData object.\n\nbrandRatingData |&gt; head()\n\n# A tibble: 6 × 3\n  Brand                avg_Rating number_Perfumes\n  &lt;chr&gt;                     &lt;dbl&gt;           &lt;int&gt;\n1 Ensar Oud / Oriscent       8.38              93\n2 Nabeel                     8.27              22\n3 Clive Christian            8.14              45\n4 Roja Parfums               8.14             118\n5 Chanel                     8.11              83\n6 Annette Neuffer            8.10              20\n\n\nIs anything different between what you expected and/or described and what the object looks like?\n\n\n\n\n\n\nVariables in tidyverse\n\n\n\n\n\nIf you are new to the tidyverse, you have expected to see more columns, but group_by() and summarize() are determining what columns are generated and saved in the new object. The two filter() calls and the arrange() call control which rows are kept and the order we see them in.\n\n\n\nWith the brandRatingData object stored, we can now proceed to visualization.",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#visualization-i",
    "href": "viz_start_to_finish.html#visualization-i",
    "title": "Start to Finish Visualizing your Data",
    "section": "Visualization I",
    "text": "Visualization I\nIn this example we will create a visualization of the top 20 perfume brands based on the average rating. The aim is to provide a novice with information about perfume brands so that they could pick a perfume with some confidence (e.g., if doing online shopping).\nIt is critically important to identify exactly what you are aiming to represent with your visualization. Biological data is often complex and, at least when publishing, space is often at a premium and figures tend to be information dense. You must consider the tension between including more information and readability.\nIn this workshop we are also aiming to create a figure that is visually appealing. We want to use elements of design such as line and colour theory etc., to capture and hold attention, whether this is during a live presentation or in a static format such as a journal.\n\nbrandRatingData |&gt; print(n = 20)\n\n# A tibble: 20 × 3\n   Brand                          avg_Rating number_Perfumes\n   &lt;chr&gt;                               &lt;dbl&gt;           &lt;int&gt;\n 1 Ensar Oud / Oriscent                 8.38              93\n 2 Nabeel                               8.27              22\n 3 Clive Christian                      8.14              45\n 4 Roja Parfums                         8.14             118\n 5 Chanel                               8.11              83\n 6 Annette Neuffer                      8.10              20\n 7 Widian / AJ Arabia                   8.09              21\n 8 Aaron Terence Hughes                 8.09              61\n 9 Areej Le Doré                        8                 24\n10 Teone Reinthal Natural Perfume       7.92              25\n11 Stéphane Humbert Lucas               7.86              27\n12 Amouage                              7.86              92\n13 Jean Patou                           7.85              28\n14 Coty                                 7.84              25\n15 Swiss Arabian                        7.84              40\n16 Houbigant                            7.83              26\n17 Guerlain                             7.80             296\n18 Ormonde Jayne                        7.78              60\n19 Ex Nihilo                            7.77              40\n20 Afnan Perfumes                       7.77              29\n\n\n\nBuilding a visualization - sketch I\nTo start a visualization I will ‘sketch’ a figure to determine different ways to display the data. A boxplot is a great place to start since I know we are showing average ratings (even though we have so far calculated based on the mean and a boxplot uses medians).\n\nggplot(data = perfume_brand_data,\n       mapping = aes(x = Rating_Value, y = Brand)) +\n  geom_boxplot()\n\nWarning: Removed 563 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nExercise: Why is this a poor visualization, and what can be done to improve it?\n\n\n\n\n\n\nCriticizing the boxplot\n\n\n\n\n\nLack of title, axis labels are ugly with underscore, no colour.\nUnsorted data is mentally tiring.\nOne-dimensional: does not show anything other than the median and summary.\nHow could this be improved?\nAdditional arguments in ggplot control title, set text size, etc.,.\nSort data and include other data to provide the reader with additional, useful information.\nSelect a clear, visually appealing colour scheme. Make sure colours are accessible, will work on other devices, text will be clear whether online or printed.\n\n\n\nFundamentally, I don’t think the boxplot works. While it does show the median and summary values, I don’t see a way to clearly show information like the number of perfumes (and, since that was a filtering criteria, I think it’s worth showing) or to make it visually interesting.\n\n\nBuilding a visualization - sketch II\nNote: In reality you might sketch out a handful of different plots to find one that suits. Here we will jump ahead to something I think works.\nFirst, we will switch to using brandRatingData, where we have calculated the Brand average rating, and we will show the average with a geom_point function. You will see that while we lose some information switching from a boxplot to a geom_point() plot, this will allow us to include other information which may be more informative.\nbrandRatingData is already formated to have Brands arranged by avg_Rating, but in case that wasn’t true, the code includes reorder() to sort by avg_Rating.\nThe labs() function is used to add a title, and clearer x and y axis labels.\n\nggplot(brandRatingData, \n       aes(x = avg_Rating, y = reorder(Brand, avg_Rating))) +\n  geom_point(aes(size = number_Perfumes, color = avg_Rating)) +\n  labs(\n    x = \"Brand rating\",\n    y = \"Brand\",\n    title = \"Mean perfume rating by brand\"\n  ) \n\n\n\n\n\n\n\n\nBy mapping average rating and the number of perfumes to colour and size (within the geom_point() function), we make the figure more visually interesting and more informative. For example, we can see that Ensar Oud/Oriscent has plenty of perfumes to choose from, while Nabeel has fewer. The plot overall looks ‘cleaner’ and less cluttered, yet actually includes more information.\nThis is the basis for a good visualization.\n\n\nRefining geom_point()\nHere we will bring in a handful of new arguments and functions. Remember that the main goal for you is not to memorise all of this information - this is a template for you to have available. Let’s look at some of the arguments below, and discuss the impact:\n\nggplot(brandRatingData, \n       aes(x = avg_Rating, y = reorder(Brand, avg_Rating))) +\n  geom_point(aes(size = number_Perfumes, color = avg_Rating)) +\n  scale_color_gradient(low = \"lightblue\", high = \"darkblue\", name = \"Brand rating\") +\n  scale_size(range = c(1, 10), name = \"Number of perfumes\") +\n  labs(\n    x = \"Brand rating\",\n    y = \"Brand\",\n    title = \"Mean perfume rating by brand\"\n  ) +\n  theme_light() +\n  theme(\n    axis.text.y = element_text(size = 10),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = \"none\")\n\n\n\n\n\n\n\n\n\nscale_color_gradient() is a function to set colours through a given gradient. Useful if you have an overall brand or theme colour (e.g., University of Otago tends to use blue and gold, so I’ve chosen blue).\nscale_size() provides control over the size of the geom_point data points. We can set the upper/lower limits, and the ‘granularity’ (i.e., a difference between a large and a small value by having a greater range). Larger point sizes here (compared to our first plot) make the figure look less empty. Having points that overlap (Guerlain) may not be appropriate in all settings, but visually it makes the plot less ‘rigid’ and is more interesting. Note this function also sets the name to “Number of perfumes”.\nBy controlling both size and colour, the new plot focuses our attention, starting at the darker top right and letting our eyes move down and to the left (which is loosely our order of preference for brands). You can switch dark and light blue and re-build the plot, notice how much it impacts where our attention is drawn!\ntheme_light() sets the background space of the plot to white rather than a darker gray. Test this by changing it to theme_dark(). There are a set of available pre-made themes, and we can also control our own themes.\ntheme() is used to control almost everything else within the plot. Here we are setting three different sizes: the plot title, the axis names, and the axis text. Title and names are further differentiated by setting typeface to bold. This highlights an important feature of design: we naturally look for patterns and similarities, therefore we can use a point of difference to make something stand out.\nguides() is being used here to remove colour from the legend (color = “none”). Use size = “none” to remove the size legend. We have done this because while colour is being used to add visual interest, it isn’t really providing us with novel information (it is repeating the same information we get from looking at where the point sits on the x axis).\n\nUsing this information as a guide, you could make many fine scale tweaks to your plot, changing it to suit your specific data and situation.\n\n\nRefining our use of the data\nLooking at this plot, what can I do to enhance the visuals to be cleaner, more dynamic, more eye-catching, more aesthetic? Is there any other data I can include to improve the plot?\nCurrently, colour is not being fully utilised - it is mapped to the Brand average rating, which is already shown via the x axis. Thinking back to earlier themes on number of ratings and number of perfumes per brand, we could use colour to represent some of our data around the rating_Count variable.\nTo do this, we will re-build the brandRatingData object with an additional variable calculated by the summarize() function, calling it avg_rating_count and then map it to colour.\n\n# Add a new summarize output: the average rating count.\nbrandRatingData &lt;- parfumo_data_clean |&gt; \n  filter(Rating_Count &gt;= 19 ) |&gt; \n  group_by(Brand) |&gt; \n  summarize(avg_Rating = mean(Rating_Value, na.rm = TRUE),\n            number_Perfumes = n(),\n            avg_rating_count = mean(Rating_Count)) |&gt; \n  filter(number_Perfumes &gt;= 20) |&gt; \n  arrange(desc(avg_Rating)) |&gt; \n  head(n = 20)\n\nBefore we map avg_rating_count to colour we will consider accessibility. A colour palette, or visualization in general, is accessible if it is something that everyone can see. The most regularly discussed examples of accessibility include text size, a colour palette that can be seen by colour-blind individuals, and more recently whether the image is gentle or overwhelming.\n\n\n\n\n\n\nTip\n\n\n\nFor an example of ‘gentle vs overwhelming’, go to Tools, Global Options, Appearance, and in the Editor theme box, check “Gob”. I personally would not enjoy spending time looking at my RStudio console if the editor was stuck in “Gob”, and I prefer the much more gentle Idle Fingers theme.\n\n\nThe viridis R package is one example of a package that claims* to have colour-blind friendly colour palettes (* I’m not colour-blind and cannot confirm). In addition to mapping avg_rating_count to colour and using the scale_color_viridis() function with the “magma” argument, I’ve also tweaked some of the arguments in theme() to make the overall text package look cleaner and softer.\n\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nlibrary(ggtext)\n\nggplot(brandRatingData, \n       aes(x = avg_Rating, y = reorder(Brand, avg_Rating))) +\n  geom_point(aes(size = number_Perfumes, color = avg_rating_count)) +\n  scale_color_viridis(option = \"magma\", direction = -1, name = \"Mean number of ratings\") +\n  scale_size(range = c(1, 10), name = \"Number of perfumes\") +\n  labs(\n    x = \"Brand rating\",\n    y = \"Brand\",\n    title = \"Top 20 Perfume Brands Ranked by Mean Rating\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 10, color = \"gray40\"),\n    axis.title = element_text(size = 12, face = \"bold\", color = \"gray50\"),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5, color = \"gray50\"),\n    legend.title = element_text(size = 12, face = \"bold\", color = \"gray50\"), \n    legend.text = element_text(size = 10, color = \"gray40\")\n  ) \n\n\n\n\n\n\n\n\nThis version of the visualization is:\n\nmore visually interesting, with eye catching colours.\nsimultaneously softer and more gentle, more accessible overall.\ndisplays more data: importantly, we can now see that Ensar Oud/Oriscent has a low average number of ratings. With this in mind, I’d be more inclined to look at Roja Parfums or Chanel over Ensar Oud.\nsuitable for conveying the basic information (Brand rating) at a glance. Even if a reader didn’t take note of the colours and sizes of the points, they would still get an idea of brand rating.",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#visualization-iii",
    "href": "viz_start_to_finish.html#visualization-iii",
    "title": "Start to Finish Visualizing your Data",
    "section": "Visualization III",
    "text": "Visualization III\nAdding skills from Cedric’s Evolution of a boxplot (mean line, text, arrows).",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#conclusion",
    "href": "viz_start_to_finish.html#conclusion",
    "title": "Start to Finish Visualizing your Data",
    "section": "Conclusion",
    "text": "Conclusion\nRecap: here’s the initial plot. Does it display the data? Yes.\nHere’s the finished product, does it convey the data? Heck yes it does!\nThe goal isn’t just to show the data. It’s to excite the audience, to capture and retain attention in an extremely noisy world. This is a visualization I’m proud of.",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_start_to_finish.html#final-exercise",
    "href": "viz_start_to_finish.html#final-exercise",
    "title": "Start to Finish Visualizing your Data",
    "section": "Final exercise",
    "text": "Final exercise\nUse the information we have discussed, and the lessons from earlier, to trial out some different geoms and visualization styles. See what code you can apply (e.g., changing size/colour) with other geoms.",
    "crumbs": [
      "Start to Finish Visualizing your Data"
    ]
  },
  {
    "objectID": "viz_1_ggplot.html",
    "href": "viz_1_ggplot.html",
    "title": "Visualization with ggplot2",
    "section": "",
    "text": "In this section we will cover the basic format of ggplot functions. We will note the format and key arguments. This code will be repeated throughout the workshop, and provided frequently as a template: therefore, the goal is not to memorise, but to be able to recognise and interpret while we build in complexity throughout the day.",
    "crumbs": [
      "Visualization with ggplot2"
    ]
  },
  {
    "objectID": "viz_1_ggplot.html#the-ggplot-format",
    "href": "viz_1_ggplot.html#the-ggplot-format",
    "title": "Visualization with ggplot2",
    "section": "The ggplot format",
    "text": "The ggplot format\nMany modern R workshops include a section on the Grammer of Graphics, or the ggplot2 function, and there is no shortage of detailed workshops and tutorials available if you want more detailed explanations of the basics.\nggplot2 is a way to create visualisations within the tidyverse. Once you recognise the template it will become quick and easy to create a variety of plots with different data types with minimal extra work.\nThe format for the ggplot2 template is as follows:\n\nspecify the data\nmap variables e.g., map a column the x axis\ncreate the plot\n\n\n# The code to create a plot, using the template above:\nggplot(data = penData,\n       mapping = aes(x = species,\n                     y = bill_length_mm)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n# Here we have specified that the data will come from the penData object\n# Data from the species variable will be on the x axis\n# Data from the bill_length_mm variable will be on the y axis\n# The type of plot is a boxplot  \n\nSome things to note about the format:\n\nIndentations are important. We use new lines and tabs to keep the code organised. Generally you’ll want to specify only one thing per line (e.g., data, x axis and y axis get there own lines).\nThe ggplot formula is a slight break away from the use of pipes.\nThere are actually two separate functions here: the ggplot() function, which is used to specify the data and map the variables, and the geom_boxplot() function which is used to create the actual plot. Because we want these two functions to work together, at the very end of the ggplot() function, we have added a “+” symbol. RStudio interprets this to mean “Ok, the ggplot function has finished, but I need to read it in the context of the next function”.\ngeom_boxplot() is the function for making boxplots. To make a bar plot we would use geom_bar(), to make a scatter plot we use geom_point() etc.,. Type geom_ in the console and scroll the dropdown menu to see the different geom types - there are plenty!",
    "crumbs": [
      "Visualization with ggplot2"
    ]
  },
  {
    "objectID": "viz_1_ggplot.html#extending-the-ggplot-format",
    "href": "viz_1_ggplot.html#extending-the-ggplot-format",
    "title": "Visualization with ggplot2",
    "section": "Extending the ggplot format",
    "text": "Extending the ggplot format\nWe can extend the plot in three easy ways:\n\nMapping additional data to variables (e.g., species or sex to variables such as colour and shape)\nSupplying additional arguments to the geom function (e.g., changing the size, colour or opacity of dots)\nAdd new functions that control features such as the title or axes labels.\n\nIn all cases, these new arguments and functions follow the template as outlined above. We will continue to use indentations and new lines to keep our code organised and tidy.\nThis example creates a more complex plot, but these new arguments and functions follow the template as outlined above. We continue to use indentations and new lines to keep our code organised and tidy.\n\n# Load the viridis library, which supplies a colour scheme that is sensitive to colour-blindness.\nlibrary(viridis)\n\nLoading required package: viridisLite\n\n# New arguments map species to the colour variable, so that each point is coloured by species.\n# Sex is mapped to shape. Note that shape can only take discrete variables.\nggplot(data = penData,\n       mapping = aes(x = bill_length_mm,\n                     y = flipper_length_mm,\n                     colour = species,\n                     shape = sex)) +\n  geom_point(size = 2, alpha = 0.6) +\n  scale_colour_viridis(discrete = TRUE) +\n  labs(x = \"Bill depth (mm)\",\n       y = \"Flipper length (mm)\") +\n  ggtitle(\"Bill depth vs flipper length\")",
    "crumbs": [
      "Visualization with ggplot2"
    ]
  },
  {
    "objectID": "viz_1_ggplot.html#showcase",
    "href": "viz_1_ggplot.html#showcase",
    "title": "Visualization with ggplot2",
    "section": "Showcase",
    "text": "Showcase\nWhat exactly can we produce with ggplot2?\n\nGalleries, books, workshops\nhttps://r-graph-gallery.com/ggplot2-package.html\nThe R graph gallery has a section on ggplot and it highlights some of the exciting features: custom fonts, pre-built themes, interactive plots - there’s a lot going on.\n\n\nFrom the community\nhttps://www.cedricscherer.com/top/dataviz/#SciAm\nWhen looking through this gallery, note that while some plots are very complex, they are built from basic elements. Each visualization is carefully designed: colour palettes are interesting but not overwhelming. There is adequate spacing between plot space and titles, axes, and text. Paler text (grey instead of black) makes overall images gentler. Cédric is a master of design as well as code, and all these visualizations demonstrate careful thought and planning.\nhttps://towardsdatascience.com/explaining-my-favourite-tidytuesday-projects-e44bfe988813\nIsaac Arrayo gives us a breakdown of four plots from #tidytuesday (a community effort where people are invited to create visualizations of a provided dataset). We see four diverse plot types, the rationale for each plot, and how these plots might be applied to a more ‘standard’ dataset (i.e., an in-real-life example).",
    "crumbs": [
      "Visualization with ggplot2"
    ]
  },
  {
    "objectID": "blog/first-post/index.html",
    "href": "blog/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "Sed risus ultricies tristique nulla aliquet. Neque volutpat ac tincidunt vitae semper quis lectus nulla.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Enim sed faucibus turpis in eu mi bibendum neque. Ac orci phasellus egestas tellus rutrum tellus pellentesque eu. Velit sed ullamcorper morbi tincidunt ornare massa. Sagittis id consectetur purus ut faucibus pulvinar elementum integer. Tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada proin libero. Lobortis feugiat vivamus at augue eget arcu. Aliquam ut porttitor leo a diam sollicitudin tempor id eu. Mauris a diam maecenas sed enim ut sem viverra aliquet. Enim ut tellus elementum sagittis vitae et leo duis. Molestie at elementum eu facilisis sed odio morbi quis commodo. Sapien pellentesque habitant morbi tristique senectus. Quam vulputate dignissim suspendisse in est. Nulla pellentesque dignissim enim sit amet venenatis urna cursus eget.\nVelit aliquet sagittis id consectetur purus ut faucibus pulvinar elementum. Viverra mauris in aliquam sem fringilla ut morbi tincidunt augue. Tortor at auctor urna nunc id. Sit amet consectetur adipiscing elit duis tristique sollicitudin. Aliquet nibh praesent tristique magna sit amet purus. Tristique senectus et netus et malesuada fames ac turpis. Hac habitasse platea dictumst quisque. Auctor neque vitae tempus quam pellentesque nec nam aliquam. Ultrices tincidunt arcu non sodales neque sodales ut etiam. Iaculis at erat pellentesque adipiscing. Cras tincidunt lobortis feugiat vivamus. Nisi est sit amet facilisis magna etiam. Pharetra pharetra massa massa ultricies mi quis hendrerit. Vitae sapien pellentesque habitant morbi tristique senectus. Ornare aenean euismod elementum nisi quis eleifend quam adipiscing vitae."
  },
  {
    "objectID": "viz_2_exploratoryAnalysis.html",
    "href": "viz_2_exploratoryAnalysis.html",
    "title": "Visualization for ourselves - Exploratory Analysis",
    "section": "",
    "text": "Visualization is most often thought of as something we do for other people, to share some piece of knowledge we have. But equally important is the role visualization can play in us learning something about our data. Visualization can reveal trends or associations that we would otherwise struggle to identify in observations stored in rows and columns.\nIn this section we will perform some quick data transformations and create some simple visualizations. The output of this section does not need to be overly attractive, but it does need to be clear and should ‘standalone’ (i.e., should speak for itself, without the need of accompanying notes).\nExploratory analysis is itself a highly useful skill, but it is also important to get some experience with data transformation - we will only rarely be lucky enough to get data in a format for visualization.\nNote: The aims for this section are to give you the opportunity to practice some of the most important code used in visualizations and to force you to think about visualization: what types of figures work well for certain data, how to display the information you want to convey.",
    "crumbs": [
      "Visualization for ourselves - Exploratory Analysis"
    ]
  },
  {
    "objectID": "viz_3_exemplarVisualizations.html",
    "href": "viz_3_exemplarVisualizations.html",
    "title": "Exemplar visualizations - what far can we take it?",
    "section": "",
    "text": "We’ve seen how to make ‘quick and dirty’ plots for ourselves. Now we will give you a glimpse of just how far you can take your visualizations. For this section we are looking at both code complexity and fundamental elements of design. The aim is to create visualizations that are clear and concise, which are also able to capture and hold attention.\nHere we will provide guidelines on design and visualization while highlighting key examples from the scientific community. All code will be easily accesible for you to use as templates for your future work.\nAn example",
    "crumbs": [
      "Exemplar visualizations - what far can we take it?"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "From Start to Finish: Visualizing Your Data",
    "section": "",
    "text": "Good visualization is about more than just writing the correct code. Visualization is communication, and good communication requires thinking about how we as the scientist/data analyst/creator convey our message to the reader. This one-day workshop will provide you with a toolbox of skills and code examples to help you create clear, visually interesting visualizations which accurately communicate a message."
  },
  {
    "objectID": "index.html#this-workshop-has-four-components",
    "href": "index.html#this-workshop-has-four-components",
    "title": "From Start to Finish: Visualizing Your Data",
    "section": "This workshop has four components",
    "text": "This workshop has four components\nThe basic code template for ggplot.\nVisualization for our selves (exploratory analysis).\nExamples of good visualization (with code).\nVisualizing your own data."
  },
  {
    "objectID": "index.html#why-are-we-doing-this",
    "href": "index.html#why-are-we-doing-this",
    "title": "From Start to Finish: Visualizing Your Data",
    "section": "Why are we doing this?",
    "text": "Why are we doing this?\nBecause some plots look like this (Credit to Dr. Joseph Guhlin for this presentation)."
  },
  {
    "objectID": "blog/third-post/index.html",
    "href": "blog/third-post/index.html",
    "title": "Third Blog Post",
    "section": "",
    "text": "The source for any page in your website could also be a Jupyter Notebook. This one is third-post/index.ipynb.\nHere’s an example I borrowed from the Seaborn docs:\n\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\")\n\n# Load the diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Plot the distribution of clarity ratings, conditional on carat\nsns.displot(\n    data=diamonds,\n    x=\"carat\", hue=\"cut\",\n    kind=\"kde\", height=4, aspect=1.5,\n    multiple=\"fill\", clip=(0, None),\n    palette=\"ch:rot=-.25,hue=1,light=.75\",   \n)"
  },
  {
    "objectID": "blog/second-post/index.html",
    "href": "blog/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Amet cursus sit amet dictum sit amet. Eget duis at tellus at urna condimentum. Convallis aenean et tortor at risus viverra. Tincidunt ornare massa eget egestas purus viverra accumsan. Et malesuada fames ac turpis egestas. At imperdiet dui accumsan sit amet. Ut ornare lectus sit amet est placerat. Enim nulla aliquet porttitor lacus luctus accumsan tortor posuere. Duis ultricies lacus sed turpis tincidunt id aliquet risus. Mattis enim ut tellus elementum sagittis. Dui id ornare arcu odio ut. Natoque penatibus et magnis dis. Libero justo laoreet sit amet cursus sit. Sed faucibus turpis in eu. Tempus iaculis urna id volutpat lacus laoreet.\nPhasellus vestibulum lorem sed risus. Eget felis eget nunc lobortis mattis. Sit amet aliquam id diam maecenas ultricies. Egestas maecenas pharetra convallis posuere morbi. Etiam erat velit scelerisque in dictum non consectetur a erat. Cras fermentum odio eu feugiat pretium nibh ipsum consequat. Viverra accumsan in nisl nisi scelerisque. Et netus et malesuada fames ac. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Eget lorem dolor sed viverra ipsum nunc aliquet. Ultrices dui sapien eget mi proin sed libero enim sed. Ultricies mi eget mauris pharetra et ultrices neque. Ipsum suspendisse ultrices gravida dictum. A arcu cursus vitae congue mauris rhoncus aenean vel. Gravida arcu ac tortor dignissim convallis. Nulla posuere sollicitudin aliquam ultrices."
  },
  {
    "objectID": "viz_4_building_better.html",
    "href": "viz_4_building_better.html",
    "title": "Building Better Plots",
    "section": "",
    "text": "Note to self: The purpose of this episode is to:\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntop_group_counts &lt;- read.delim(\"https://raw.githubusercontent.com/tylermcinnes/visualization_day/refs/heads/main/data/eDNA_group_counts.tsv\")\nThis section follows the outline produced by the very skilled data visualizer Cédric Scherer, modified to work with some example data and updated with my own thoughts and opinions. Cédric’s original tutorial is available here:\nhttps://www.cedricscherer.com/2019/05/17/the-evolution-of-a-ggplot/\n# Verify that all groups have 500 observations\ntop_group_counts |&gt; group_by(Group) |&gt; summarize(observations = n(), .groups = \"drop\") |&gt; arrange(desc(observations)) |&gt; head()\n\n# A tibble: 6 × 2\n  Group    observations\n  &lt;chr&gt;           &lt;int&gt;\n1 Birds             500\n2 Ciliates          500\n3 Diatoms           500\n4 Fish              500\n5 Insects           500\n6 Mammals           500\nInitial plot of the data:\nggplot(data = top_group_counts,\nmapping = aes(x = Group, y = Count)) +\ngeom_boxplot()\nTaking the log of Count data makes this clearer:\nggplot(data = top_group_counts,\nmapping = aes(x = Group, y = log(Count))) +\ngeom_boxplot()\nIt’s often worth representing boxplots on a horizontal, rather than vertical, distribution. Let’s switch our axes assignments:\nggplot(data = top_group_counts,\nmapping = aes(x = log(Count), y = Group)) +\ngeom_boxplot()\nGenerally we will find that sometimes switching the layout like this can provide us with clearer visualization, sometimes due to labels, sometimes for aesthetics.",
    "crumbs": [
      "Building Better Plots"
    ]
  },
  {
    "objectID": "viz_4_building_better.html#better-visualization",
    "href": "viz_4_building_better.html#better-visualization",
    "title": "Building Better Plots",
    "section": "Better visualization",
    "text": "Better visualization\nWe can now start to focus on the visualization aspects: control plot themes such as labels, titles, spacing. We can explore geoms, and variations on geoms, to determine the best way to present the data. Finally, we can add additional geoms or mappings to display more data.\n\nTheme\nTheme is a separate function that controls almost all visual elements of a ggplot. We can fine tune text elements (font size, shape, angle for axis text, create custom labels and titles), the legend (changing the position, setting a background, control the title and content), the ‘panel’ (panel is the background of the plot, in the above cases we have a grid), and many other features.\nA useful tip for working with ggplot is to save a set of basic features, such as the data, mapping, and theme to an object which can then be used for plotting with different geoms later. Notice below we use a slightly different format for writing our ggplot function - we omit “data =” and “mapping =”, since those calls are always required and used.\nFor simplicity we will also reduce our total dataset down to just\n\ngroupCounts &lt;- ggplot(top_group_counts_sorted, aes(x = log(Count), y = Group, colour = Group)) +\n  labs(title = \"eDNA counts vary across species groups\",\n       x = \"log(Count)\", \n       y = \"Group\") +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 10),\n    panel.grid = element_blank()\n  ) \n\n# Note, no plot is created yet. We will now use the groupCounts object in combination with geom functions to create plots.\n\nWe can now trial different geoms to determine which type suits our visualization needs.\n\ngroupCounts + \n  geom_boxplot() \n\n\n\n\n\n\n\n\n\ngroupCounts + \n  geom_violin() \n\n\n\n\n\n\n\n\n\ngroupCounts + geom_line()\n\n\n\n\n\n\n\n\n\ngroupCounts + geom_point()\n\n\n\n\n\n\n\n\nA particularly useful argument with the geom_point() function is alpha, which controls the opacity/transparency of the points. With reduced opacity we can see more clearly when points are placed on top of one another. It is less clear in this example because there are so many data points in a small space, but it’s usefulness will become more apparent shortly.\n\ngroupCounts + geom_point(size = 3, alpha = 0.2)\n\n\n\n\n\n\n\n\n\n\nCombining geoms\nGeoms can be combined to create more complex plots by layering one set of information over another.\n\ngroupCounts + \n  geom_boxplot(colour = \"gray\", outlier.alpha = 0) +\n  geom_point(size = 3, alpha = 0.2)\n\n\n\n\n\n\n\n\nNote that we’ve included a new argument in geom_boxplot(): “outlier.alpha = 0”. The boxplot geom normally adds points that are considered outliers (greater than 1.5 times the interquartile range above or below the 1st or 3rd quartile). Since these points are going to be represented by the geom_point() function, we need to set outlier.alpha to 0 so that they are functionally invisible (and are therefore not printed twice).\nWhile the above demonstrates the concept of combining geoms, it’s not very functional. The high density of our points on a straight line is creating a strong effect that is over-powering other visualizations. We can change the points from being on a single line to spaced apart with the geom_jitter() function.\n\ngroupCounts + geom_jitter(size = 2, alpha = 0.2, width = 0.2)\n\n\n\n\n\n\n\n\n\ngroupCounts + \n  geom_boxplot(colour = \"gray40\", outlier.alpha = 0) +\n  geom_jitter(size = 2, alpha = 0.2, width = 0.2)\n\n\n\n\n\n\n\n# gray40 is a darker gray that is not quite black. I had to test multiple colours to find one that was clearly visible but not overwhelming.\n\n\n\n(Even) more geoms\nThere are some really cool things we can do by combining geoms, and here your imagination and creativity is (probably) the limiting factor rather than ggplot.\nLet’s look at how each of our Groups compares to the average (and in this case, we will use mean instead of the median we have been using with our box plots).\nFirst, we will visualize the Group means with the stat_summary function.\n\ngroupCounts +\n  geom_jitter(size = 2, alpha = 0.2, width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", size = 5, colour = \"gray40\")\n\n\n\n\n\n\n\n\nNote: here we have selected the size of the stat_summary point as 5, but we could also provide a set of values (e.g., if we had different numbers of observations per group).\nNext, we can add the overall mean for these groups as a vertical line:\n\n# Calculate the average number of Counts across all samples. \ntop10_group_avg &lt;- top_group_counts_sorted |&gt; \n  summarize(t10_avg = mean(log(Count))) |&gt; \n  pull(t10_avg)\n\ngroupCounts +\n  geom_vline(aes(xintercept = top10_group_avg), colour = \"gray50\", size = 0.6) +\n  stat_summary(colour = \"gray40\",fun = mean, geom = \"point\", size = 5) +\n  geom_jitter(size = 2, alpha = 0.2, width = 0.2)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nGeom order matters! Note how the summary points (black) are obscured by the coloured points produced by geom_jitter()? We can switch the order so that the jitter points are drawn first, and the summary points placed on top.\n\ngroupCounts +\n  geom_jitter(size = 2, alpha = 0.2, width = 0.2) +\n  geom_vline(aes(xintercept = top10_group_avg), colour = \"gray50\", size = 0.6, alpha = 0.8) +\n  stat_summary(colour = \"gray50\",fun = mean, geom = \"point\", size = 5, alpha = 0.75)\n\n\n\n\n\n\n\n\nIf we are trying to highlight the difference between a Group mean and the global mean, this can be amplified by adding text to our image.\n\ngroupMeans &lt;- top_group_counts_sorted |&gt; group_by(Group) |&gt; summarise(groupMean = log(mean(Count))) |&gt; pull(groupMean)\n\ngroupCounts +\n  geom_jitter(size = 2, alpha = 0.2, width = 0.2) +\n  geom_vline(aes(xintercept = top10_group_avg), colour = \"gray50\", size = 0.6, alpha = 0.8) +\n  stat_summary(colour = \"gray60\",fun = mean, geom = \"point\", size = 5, alpha = 0.8) +\n  annotate(\n    \"text\", x = 7.8, y = 10, size = 2.8, color = \"gray20\", lineheight = .9,\n    label = glue::glue(\"Counts for fish are significantly higher\\nthan other groups (7.6)\")\n  ) +\n    annotate(\n    \"text\", x = 5.25, y = 1, size = 2.8, color = \"gray20\",\n    label = \"Total group average (4.2)\"\n  )\n\n\n\n\n\n\n\n\nThis isn’t necessarily something you would do in many types of plots, but is useful to draw attention to key points (often, e.g., a single gene of interest in a scatter plot).\n\nggsave(\"boxplot.png\", height = 10, width = 8)",
    "crumbs": [
      "Building Better Plots"
    ]
  }
]